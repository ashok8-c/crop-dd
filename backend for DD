import os
import cv2
import numpy as np
import joblib
import json
import logging
import time
from tqdm import tqdm
from skimage.feature import hog
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

# --- Configuration ---
dataset_path = r"C:\Users\ashky\OneDrive\Desktop\CROP D D\PlantVillage"
model_path = r"C:\Users\ashky\OneDrive\Desktop\CROP D D\models\svm_crop_disease.pkl"
json_file = r"C:\Users\ashky\OneDrive\Desktop\CROP D D\crop_diseases.json"
img_size = (150, 150)

# ‚úÖ Logging Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_features(img):
    """Extracts HOG features from an image."""
    img = cv2.resize(img, img_size)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = img / 255.0  # Normalize pixel values
    features = hog(img, pixels_per_cell=(16, 16), cells_per_block=(2, 2), feature_vector=True)
    return features

def load_dataset():
    """Load images from folders, extract features, and assign labels."""
    images, labels = [], []
    label_map = {}
    if not os.path.exists(dataset_path):
        logging.error(f"‚ùå Dataset path not found: {dataset_path}")
        return np.array(images), np.array(labels), label_map

    for idx, category in enumerate(os.listdir(dataset_path)):
        category_path = os.path.join(dataset_path, category)
        if not os.path.isdir(category_path):
            continue  
        label_map[idx] = category
        img_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        logging.info(f"üìÇ Loading category: {category} ({len(img_files)} images)")

        for img_name in tqdm(img_files, desc=f"üìÇ Loading {category}", unit="img"):
            img_path = os.path.join(category_path, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                images.append(extract_features(img))
                labels.append(idx)
            else:
                logging.warning(f"‚ö† Skipping invalid image: {img_name}")
    
    return np.array(images), np.array(labels), label_map

def train_model():
    """Train the SVM classifier and save it."""
    print("\nüõ† Training the model...")
    X, y, label_map = load_dataset()
    if len(X) == 0 or len(y) == 0:
        print("‚ùå No data loaded. Check the dataset path.")
        return
    
    print("‚úÖ Data loaded successfully! Splitting into training and testing sets...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print("üöÄ Training the SVM model...")
    start_time = time.time()
    svm_model = SVC(kernel='linear', probability=True)
    svm_model.fit(X_train, y_train)
    end_time = time.time()
    
    print(f"‚è± Training time: {end_time - start_time:.2f} seconds")
    accuracy = svm_model.score(X_test, y_test) * 100
    print(f"üìä Final Model Accuracy: {accuracy:.2f}%")
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump((svm_model, label_map), model_path)
    print(f"‚úÖ Model saved at: {model_path}")

def load_disease_info():
    """Load disease information from JSON file."""
    try:
        with open(json_file, 'r') as file:
            return json.load(file)
    except FileNotFoundError:
        logging.error(f"‚ùå JSON file not found: {json_file}")
        return {}

def predict_disease(image_path):
    """Predict disease from an image using trained SVM model."""
    if not os.path.exists(model_path):
        logging.error(f"‚ùå Model not found: {model_path}")
        return
    
    try:
        model, label_map = joblib.load(model_path)
    except Exception as e:
        logging.error(f"‚ùå Error loading model: {str(e)}")
        return
    
    if not os.path.exists(image_path):
        logging.error(f"‚ùå Image not found: {image_path}")
        return
    
    img = cv2.imread(image_path)
    if img is None:
        logging.error(f"‚ùå Unable to read image: {image_path}")
        return
    
    features = extract_features(img).reshape(1, -1)
    prediction = model.predict(features)[0]
    confidence = np.max(model.predict_proba(features)) * 100
    disease_name = label_map[prediction]
    
    disease_info = load_disease_info().get(disease_name, {})
    logging.info(f"\nüåø Disease: {disease_name}")
    logging.info(f"üîç Confidence: {confidence:.2f}%")
    
    if disease_info:
        logging.info("‚ö† Precautions:")
        for step in disease_info.get("precautions", []):
            logging.info(f"- {step}")
    else:
        logging.info("No information available.")

if __name__ == '__main__':
    if not os.path.exists(model_path):
        train_model()
    
    test_image = r"C:\Users\ashky\OneDrive\Desktop\CROP D D\yellow curly.jpg"
    logging.info("\nüîé Predicting disease for: " + test_image)
    predict_disease(test_image)
